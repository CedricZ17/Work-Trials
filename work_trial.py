# -*- coding: utf-8 -*-
"""Work Trial.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18K03ogbedHA8tgyKukiQ0TbUiZSGs0TT
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
import matplotlib.pyplot as plt
uploaded_file = 'merged_data.csv'
data = pd.read_csv(uploaded_file)

"""Q1"""

# Calculate price impact
data['price_impact'] = data['price'] - data['mid_price']

# Visualize distribution of price impact
plt.figure(figsize=(10, 6))
plt.hist(data['price_impact'], bins=50, alpha=0.7, color='blue', edgecolor='black')
plt.title('Distribution of Price Impact', fontsize=14)
plt.xlabel('Price Impact', fontsize=12)
plt.ylabel('Frequency', fontsize=12)
plt.grid(alpha=0.3)
plt.show()

# Linear OW Model
X = data['Signed Volume'].values.reshape(-1, 1)
y = data['price_impact'].values
linear_model = LinearRegression()
linear_model.fit(X, y)
linear_price_impact = linear_model.predict(X)

# Nonlinear AFS Model (polynomial degree 2)
poly = PolynomialFeatures(degree=2)
X_poly = poly.fit_transform(X)
nonlinear_model = LinearRegression()
nonlinear_model.fit(X_poly, y)
nonlinear_price_impact = nonlinear_model.predict(X_poly)

# Visualization
plt.figure(figsize=(14, 7))
plt.scatter(data['Signed Volume'], data['price_impact'], alpha=0.5, label='Actual Data', color='gray')
plt.plot(data['Signed Volume'], linear_price_impact, color='blue', linewidth=2, label='Linear OW Model')
plt.plot(data['Signed Volume'], nonlinear_price_impact, color='red', linewidth=2, label='Nonlinear AFS Model')
plt.title('Linear OW Model vs Nonlinear AFS Model', fontsize=14)
plt.xlabel('Signed Volume', fontsize=12)
plt.ylabel('Price Impact', fontsize=12)
plt.legend(fontsize=12)
plt.grid(alpha=0.3)
plt.show()

"""Q2"""

# Extract relevant columns
Q = data['Signed Volume'].values
J = data['mid_price'].diff().fillna(0).values

# Define constants
beta = 0.2
gamma = 1.0
p_plus_1 = 1

# Calculate PnL_LM (C.7 in the paper)
PnL_LM = np.sum(Q[:-1] * J[1:] - beta * np.abs(Q[:-1])**p_plus_1)

# Calculate R_M (C.8 in the paper)
R_M = np.sum((gamma / 2) * Q[:-1]**2)

# Compute Sharpe Ratio (C.13 in the paper)
Sharpe_Ratio = PnL_LM / R_M

# Output the results
print(f"PnL_LM: {PnL_LM}")
print(f"R_M: {R_M}")
print(f"Sharpe Ratio: {Sharpe_Ratio}")

"""Q3"""

# Prepare data for deep learning
data['price_impact'] = data['price'] - data['mid_price']
X = data[['Signed Volume', 'mid_price']].values
y = data['price_impact'].values

# Normalize data
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# Define deep learning models with different structures
def create_model(layers, neurons, dropout_rate=0.2):
    model = Sequential()
    model.add(Dense(neurons, activation='relu', input_shape=(X_train.shape[1],)))
    for _ in range(layers - 1):
        model.add(Dense(neurons, activation='relu'))
        model.add(Dropout(dropout_rate))
    model.add(Dense(1, activation='linear'))  # Output layer
    model.compile(optimizer='adam', loss='mse', metrics=['mse'])
    return model

# Train models with different configurations
configurations = [(1, 32), (2, 64), (3, 128)]  # (number of layers, neurons per layer)
history_results = {}

for layers, neurons in configurations:
    model = create_model(layers, neurons)
    history = model.fit(X_train, y_train, epochs=20, batch_size=64, validation_split=0.2, verbose=1)
    history_results[f"{layers} Layers, {neurons} Neurons"] = history.history['val_loss']

# Visualize training loss
plt.figure(figsize=(10, 6))
for config, val_loss in history_results.items():
    plt.plot(val_loss, label=config)
plt.title('Training Loss for Different Network Structures', fontsize=14)
plt.xlabel('Epochs', fontsize=12)
plt.ylabel('Validation Loss (MSE)', fontsize=12)
plt.legend(fontsize=10)
plt.grid(alpha=0.3)
plt.show()